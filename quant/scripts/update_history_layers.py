# scripts/update_history_layers.py
# -*- coding: utf-8 -*-
"""
åŽ†å²æ•°æ®åˆ†å±‚æ›´æ–°è„šæœ¬
- æ”¯æŒå¤šæ•°æ®æºï¼ˆakshare, tushare, yfinanceï¼‰
- å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½
- åˆ†å±‚ç®¡ç†ï¼ˆcore, sector, fullï¼‰
"""
from __future__ import annotations
import os
import sys
import argparse
import time
from pathlib import Path
from datetime import datetime, timezone, date
from typing import List, Dict, Optional, Callable
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
import yaml
import pandas as pd

# è®¾ç½®UTF-8è¾“å‡ºï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®è·¯å¾„
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent  # quant/scripts -> quant -> project_root
sys.path.insert(0, str(project_root))

from quant.storage.stores import ParquetYearWriter, StoreConfig  # æ›´æ–°ä¸º stores/ æ¨¡å—

# ========== å¸¸é‡å®šä¹‰ ==========
REQUIRED_COLUMNS = ["date", "open", "high", "low", "close", "volume"]

COLUMN_MAPPING = {
    "akshare": {"æ—¥æœŸ": "date", "å¼€ç›˜": "open", "æœ€é«˜": "high", "æœ€ä½Ž": "low", "æ”¶ç›˜": "close", "æˆäº¤é‡": "volume"},
    "tushare": {"trade_date": "date", "vol": "volume"},
    "yfinance": {"Date": "date", "Open": "open", "High": "high", "Low": "low", "Close": "close", "Volume": "volume"}
}

ADJUST_MAPPING = {
    "none": "",
    "qfq": "qfq",
    "hfq": "hfq"
}

# ========== é…ç½®ç±» ==========
@dataclass
class GlobalConfig:
    """å…¨å±€é…ç½®"""
    root: str
    provider: str = "akshare"
    adjust: str = "qfq"
    interval: str = "1d"
    start: str = "2024-01-01"
    end: str = "today"
    concurrency: int = 8
    retry: int = 2
    tushare_token: Optional[str] = None
    
    @classmethod
    def from_dict(cls, data: Dict) -> GlobalConfig:
        """ä»Žå­—å…¸åˆ›å»ºé…ç½®"""
        return cls(
            root=data["root"],
            provider=data.get("provider", "akshare"),
            adjust=data.get("adjust", "qfq"),
            interval=data.get("interval", "1d"),
            start=data.get("start", "2024-01-01"),
            end=data.get("end", "today"),
            concurrency=int(data.get("concurrency", 8)),
            retry=int(data.get("retry", 2)),
            tushare_token=data.get("tushare_token") or os.getenv("TUSHARE_TOKEN")
        )

@dataclass
class LayerConfig:
    """å±‚é…ç½®"""
    path: str
    symbols: List[str] = field(default_factory=list)
    symbols_file: Optional[str] = None
    auto_discover: bool = False
    update_day_of_week: Optional[int] = None
    
    @classmethod
    def from_dict(cls, data: Dict) -> LayerConfig:
        """ä»Žå­—å…¸åˆ›å»ºé…ç½®"""
        return cls(
            path=data["path"],
            symbols=data.get("symbols", []),
            symbols_file=data.get("symbols_file"),
            auto_discover=data.get("auto_discover", False),
            update_day_of_week=data.get("update_day_of_week")
        )

# ========== åŸºç¡€æ•°æ®æå–ç±» ==========
class DataFetcher:
    """æ•°æ®æå–å™¨åŸºç±»"""
    
    @staticmethod
    def normalize_date_format(date_str: str) -> str:
        """æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼"""
        return date_str.replace("-", "")
    
    @staticmethod
    def standardize_dataframe(df: pd.DataFrame, column_mapping: Dict) -> pd.DataFrame:
        """æ ‡å‡†åŒ–DataFrame"""
        if df is None or df.empty:
            return pd.DataFrame(columns=REQUIRED_COLUMNS)
        
        # å¤åˆ¶DataFrameé¿å…ä¿®æ”¹åŽŸæ•°æ®
        df = df.copy()
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€åˆ—
        missing_cols = set(REQUIRED_COLUMNS) - set(df.columns)
        if missing_cols:
            # å¦‚æžœç¼ºå°‘åˆ—ï¼Œå¡«å……NaN
            for col in missing_cols:
                df[col] = 0 if col == "volume" else None
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[REQUIRED_COLUMNS].copy()
        
        # è½¬æ¢æ—¥æœŸå¹¶æŽ’åº
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date").drop_duplicates(subset=["date"], keep="last")
        
        return df
    
    @staticmethod
    def apply_adjust_factor(df: pd.DataFrame, factor_df: pd.DataFrame, adjust: str) -> pd.DataFrame:
        """åº”ç”¨å¤æƒå› å­"""
        if factor_df is None or factor_df.empty:
            return df
        
        # åˆå¹¶å› å­
        df = df.merge(factor_df[["date", "adj_factor"]], on="date", how="left").ffill()
        
        # è®¡ç®—å¤æƒä»·æ ¼
        base_factor = df["adj_factor"].iloc[-1]
        ratio = (df["adj_factor"] / base_factor) if adjust == "qfq" else (base_factor / df["adj_factor"])
        
        for col in ["open", "high", "low", "close"]:
            df[col] = df[col].astype(float) * ratio
        
        return df


class AkShareFetcher(DataFetcher):
    """AKShareæ•°æ®æå–å™¨"""
    
    @staticmethod
    def fetch(symbol: str, start: str, end: str, adjust: str = "qfq") -> pd.DataFrame:
        import akshare as ak
        
        # ç¡®ä¿å‚æ•°æ˜¯å­—ç¬¦ä¸²
        symbol = str(symbol)
        start = str(start)
        end = str(end)
        
        df = ak.stock_zh_a_hist(
            symbol=symbol,
            period="daily",
            start_date=DataFetcher.normalize_date_format(start),
            end_date=DataFetcher.normalize_date_format(end),
            adjust=ADJUST_MAPPING.get(adjust.lower(), "")
        )
        
        return DataFetcher.standardize_dataframe(df, COLUMN_MAPPING["akshare"])


class TuShareFetcher(DataFetcher):
    """TuShareæ•°æ®æå–å™¨"""
    
    @staticmethod
    def fetch(symbol: str, start: str, end: str, adjust: str = "qfq", token: Optional[str] = None) -> pd.DataFrame:
        import tushare as ts
        
        if token:
            ts.set_token(token)
        
        pro = ts.pro_api()
        raw = pro.daily(
            ts_code=symbol,
            start_date=DataFetcher.normalize_date_format(start),
            end_date=DataFetcher.normalize_date_format(end)
        )
        
        df = DataFetcher.standardize_dataframe(raw, COLUMN_MAPPING["tushare"])
        
        # åº”ç”¨å¤æƒ
        if adjust.lower() != "none":
            factor_df = pro.adj_factor(
                ts_code=symbol,
                start_date=DataFetcher.normalize_date_format(start),
                end_date=DataFetcher.normalize_date_format(end)
            )
            
            if factor_df is not None and not factor_df.empty:
                factor_df = factor_df.rename(columns={"trade_date": "date"})
                factor_df["date"] = pd.to_datetime(factor_df["date"])
                factor_df = factor_df.sort_values("date").ffill()
                df = DataFetcher.apply_adjust_factor(df, factor_df, adjust)
        
        return df


class YFinanceFetcher(DataFetcher):
    """Yahoo Financeæ•°æ®æå–å™¨"""
    
    @staticmethod
    def fetch(symbol: str, start: str, end: str, adjust: str = "none") -> pd.DataFrame:
        import yfinance as yf
        
        auto_adjust = (adjust.lower() != "none")
        df = yf.download(
            symbol,
            start=start,
            end=end,
            auto_adjust=auto_adjust,
            interval="1d",
            progress=False
        )
        
        df = df.reset_index()
        return DataFetcher.standardize_dataframe(df, COLUMN_MAPPING["yfinance"])


# æå–å™¨æ˜ å°„
FETCHER_MAP = {
    "akshare": AkShareFetcher.fetch,
    "tushare": TuShareFetcher.fetch,
    "yfinance": YFinanceFetcher.fetch,
}

# ========== å·¥å…·å‡½æ•° ==========
def get_today_str() -> str:
    """èŽ·å–ä»Šæ—¥æ—¥æœŸå­—ç¬¦ä¸²"""
    return datetime.now(timezone.utc).strftime("%Y-%m-%d")


def ensure_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç¡®ä¿DataFrameåŒ…å«æœ‰æ•ˆçš„OHLCVæ•°æ®
    
    Args:
        df: åŽŸå§‹DataFrame
        
    Returns:
        æ¸…æ´—åŽçš„DataFrame
    """
    if df is None or df.empty:
        return pd.DataFrame(columns=REQUIRED_COLUMNS)
    
    # éªŒè¯å¿…éœ€åˆ—
    for col in REQUIRED_COLUMNS:
        if col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€åˆ—: {col}")
    
    # æ•°æ®æ¸…æ´—
    df = df.copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df[df["date"].notna()]  # ç§»é™¤æ— æ•ˆæ—¥æœŸ
    df = df.sort_values("date").drop_duplicates(subset=["date"], keep="last")
    df = df[df["close"] > 0]  # ç§»é™¤æ— æ•ˆä»·æ ¼
    df["volume"] = df["volume"].fillna(0).astype(float)
    
    return df


def guess_exchange(symbol) -> str:
    """æ ¹æ®è‚¡ç¥¨ä»£ç æŽ¨æ–­äº¤æ˜“æ‰€"""
    symbol_str = str(symbol).upper()
    
    if symbol_str.endswith(".SZ"):
        return "SZSE"
    elif symbol_str.endswith(".SH"):
        return "SSE"
    elif symbol_str.endswith(".HK"):
        return "HKEX"
    
    # æ ¹æ®Aè‚¡ä»£ç å‰ç¼€åˆ¤æ–­
    if symbol_str.startswith("6"):
        return "SSE"  # ä¸Šäº¤æ‰€
    elif symbol_str.startswith("0") or symbol_str.startswith("2") or symbol_str.startswith("3"):
        return "SZSE"  # æ·±äº¤æ‰€
    
    return "NASDAQ"


def load_symbols_from_file(file_path: Optional[str]) -> List[str]:
    """
    ä»Žæ–‡ä»¶åŠ è½½è‚¡ç¥¨ä»£ç åˆ—è¡¨
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    if not file_path:
        return []
    
    path = Path(file_path)
    if not path.exists():
        return []
    
    symbols = []
    for line in path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            symbols.append(line)
    
    return symbols

# ========== æ›´æ–°ä»»åŠ¡ ==========
@dataclass
class UpdateTask:
    """æ›´æ–°ä»»åŠ¡"""
    symbol: str
    exchange: str
    layer_name: str


@dataclass
class UpdateResult:
    """æ›´æ–°ç»“æžœ"""
    symbol: str
    rows_appended: int = 0
    error: Optional[str] = None
    
    @property
    def success(self) -> bool:
        return self.error is None


class LayerUpdater:
    """æ•°æ®å±‚æ›´æ–°å™¨"""
    
    def __init__(self, global_config: GlobalConfig, layer_config: LayerConfig):
        self.global_config = global_config
        self.layer_config = layer_config
        self.writer = self._create_writer()
        self.fetch_fn = self._get_fetch_function()
    
    def _create_writer(self) -> ParquetYearWriter:
        """åˆ›å»ºæ•°æ®å†™å…¥å™¨"""
        store_path = Path(self.global_config.root) / self.layer_config.path
        config = StoreConfig(root=str(store_path))
        return ParquetYearWriter(config)
    
    def _get_fetch_function(self) -> Callable:
        """èŽ·å–æ•°æ®æå–å‡½æ•°"""
        provider = self.global_config.provider
        if provider not in FETCHER_MAP:
            raise ValueError(f"æœªçŸ¥çš„æ•°æ®æä¾›è€…: {provider}")
        return FETCHER_MAP[provider]
    
    def _fetch_and_save(self, task: UpdateTask) -> UpdateResult:
        """æå–å¹¶ä¿å­˜æ•°æ®"""
        try:
            # ç¡®ä¿symbolæ˜¯å­—ç¬¦ä¸²
            symbol_str = str(task.symbol)
            
            # æå–æ•°æ®
            if self.global_config.provider == "tushare":
                df = self.fetch_fn(
                    symbol_str,
                    self.global_config.start,
                    self.global_config.end,
                    self.global_config.adjust,
                    self.global_config.tushare_token
                )
            else:
                df = self.fetch_fn(
                    symbol_str,
                    self.global_config.start,
                    self.global_config.end,
                    self.global_config.adjust
                )
            
            # æ•°æ®æ¸…æ´—
            df = ensure_ohlcv(df)
            
            # ä¿å­˜æ•°æ®
            count = 0
            if not df.empty:
                count = self.writer.append(
                    task.exchange,
                    symbol_str,
                    self.global_config.interval,
                    df
                )
            
            return UpdateResult(symbol=symbol_str, rows_appended=count)
        
        except Exception as e:
            import traceback
            error_detail = f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            return UpdateResult(
                symbol=str(task.symbol),
                error=error_detail
            )
    
    def should_update(self, force: bool = False) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›´æ–°"""
        # å¦‚æžœä¸æ˜¯fullå±‚ï¼Œæ€»æ˜¯æ›´æ–°
        if not self.layer_config.update_day_of_week:
            return True
        
        # å¦‚æžœå¼ºåˆ¶æ›´æ–°ï¼Œè·³è¿‡æ—¥æœŸæ£€æŸ¥
        if force:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡å®šçš„æ›´æ–°æ—¥
        today = date.today()
        return today.weekday() == self.layer_config.update_day_of_week
    
    def get_symbols(self) -> List[str]:
        """èŽ·å–è¦æ›´æ–°çš„è‚¡ç¥¨åˆ—è¡¨"""
        symbols = list(self.layer_config.symbols)
        
        # ä»Žæ–‡ä»¶åŠ è½½
        if self.layer_config.symbols_file:
            symbols.extend(load_symbols_from_file(self.layer_config.symbols_file))
        
        # è‡ªåŠ¨å‘çŽ°ï¼ˆå ä½ï¼‰
        if self.layer_config.auto_discover and not symbols:
            raise ValueError("auto_discover=true ä½†æœªå®žçŽ°è‡ªåŠ¨å‘çŽ°åŠŸèƒ½")
        
        return symbols
    
    def update(self, force: bool = False) -> Dict:
        """æ‰§è¡Œæ›´æ–°"""
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›´æ–°
        if not self.should_update(force):
            return {
                "skipped": True,
                "reason": f"today weekday != {self.layer_config.update_day_of_week}"
            }
        
        # èŽ·å–è‚¡ç¥¨åˆ—è¡¨
        symbols = self.get_symbols()
        if not symbols:
            return {"skipped": True, "reason": "no symbols"}
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = [
            UpdateTask(
                symbol=symbol,
                exchange=guess_exchange(symbol),
                layer_name=self.layer_config.path
            )
            for symbol in symbols
        ]
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡
        results = []
        with ThreadPoolExecutor(max_workers=self.global_config.concurrency) as executor:
            future_to_task = {
                executor.submit(self._fetch_and_save, task): task
                for task in tasks
            }
            
            for future in as_completed(future_to_task):
                result = future.result()
                results.append(result)
        
        # ç»Ÿè®¡ç»“æžœ
        success_count = sum(1 for r in results if r.success)
        fail_count = sum(1 for r in results if not r.success)
        
        return {
            "skipped": False,
            "ok": success_count,
            "fail": fail_count,
            "detail": [
                {
                    "symbol": r.symbol,
                    "rows_appended": r.rows_appended,
                    "error": r.error
                }
                for r in results
            ]
        }

# ========== ä¸»ç¨‹åº ==========
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # è§£æžå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="æ›´æ–°åŽ†å²æ•°æ®åˆ†å±‚å­˜å‚¨ï¼ˆParquet + Manifestï¼‰"
    )
    parser.add_argument(
        "--config",
        default="configs/data_layers.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--only",
        default="",
        help="åªæ›´æ–°æŒ‡å®šå±‚ï¼ˆcore|sector|fullï¼‰ï¼Œé€—å·åˆ†éš”"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶æ›´æ–°ï¼ˆå¿½ç•¥fullå±‚çš„å‘¨æ›´é™åˆ¶ï¼‰"
    )
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        sys.exit(1)
    
    config_data = yaml.safe_load(config_path.read_text(encoding="utf-8"))
    
    # è§£æžå…¨å±€é…ç½®å’Œå±‚é…ç½®
    global_config = GlobalConfig.from_dict(config_data)
    layers = {
        name: LayerConfig.from_dict(data)
        for name, data in config_data.get("layers", {}).items()
    }
    
    # å¤„ç†end="today"çš„æƒ…å†µ
    if global_config.end == "today":
        global_config.end = get_today_str()
    
    # ç¡®å®šè¦æ›´æ–°çš„å±‚
    if args.only:
        layer_names = [name.strip() for name in args.only.split(",") if name.strip()]
    else:
        layer_names = list(layers.keys())
    
    # æ‰§è¡Œæ›´æ–°
    print(f"\n{'='*60}")
    print(f"ðŸ“Š åŽ†å²æ•°æ®åˆ†å±‚æ›´æ–°")
    print(f"{'='*60}")
    print(f"Provider: {global_config.provider}")
    print(f"Period: {global_config.start} ~ {global_config.end}")
    print(f"Layers: {', '.join(layer_names)}")
    print(f"{'='*60}\n")
    
    summary = {}
    start_time = time.time()
    
    for layer_name in layer_names:
        if layer_name not in layers:
            print(f"âš ï¸  è·³è¿‡æœªçŸ¥å±‚: {layer_name}")
            continue
        
        print(f"ðŸ”„ æ›´æ–°å±‚: {layer_name}")
        
        try:
            updater = LayerUpdater(global_config, layers[layer_name])
            result = updater.update(force=args.force)
            summary[layer_name] = result
            
            if result.get("skipped"):
                print(f"   â­ï¸  è·³è¿‡: {result.get('reason')}")
            else:
                ok = result.get("ok", 0)
                fail = result.get("fail", 0)
                print(f"   âœ… æˆåŠŸ: {ok} | âŒ å¤±è´¥: {fail}")
                
                # æ˜¾ç¤ºå¤±è´¥è¯¦æƒ…
                if fail > 0 and args.only:  # åªåœ¨å•å±‚æ›´æ–°æ—¶æ˜¾ç¤ºè¯¦æƒ…
                    for detail in result.get("detail", []):
                        if detail.get("error"):
                            print(f"      {detail['symbol']}: {detail['error']}")
        
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)}")
            summary[layer_name] = {"error": str(e)}
    
    # è¾“å‡ºæ€»ç»“
    elapsed = time.time() - start_time
    print(f"\n{'='*60}")
    print(f"âœ¨ å®Œæˆï¼Œè€—æ—¶ {elapsed:.1f}ç§’")
    print(f"{'='*60}")
    
    # è¯¦ç»†ç»Ÿè®¡
    for layer_name, result in summary.items():
        if result.get("error"):
            print(f"- {layer_name}: âŒ {result['error']}")
        elif result.get("skipped"):
            print(f"- {layer_name}: â­ï¸  {result['reason']}")
        else:
            ok = result.get("ok", 0)
            fail = result.get("fail", 0)
            total = ok + fail
            success_rate = (ok / total * 100) if total > 0 else 0
            print(f"- {layer_name}: âœ… {ok}/{total} ({success_rate:.1f}%)")


if __name__ == "__main__":
    main()

